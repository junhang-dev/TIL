# AI 에이전트의 가드레일(Guardrail) 필요성

## 📚 배운 것 (Facts)

- AI 에이전트(Agent)에게 **가드레일(Guardrail)**, 즉 안전장치를 설정하는 것은 매우 중요하다.
- 가드레일은 AI 에이전트가 **의도된 역할과 범위(Scope)를 벗어나는 행동을 하지 않도록** 제어하는 핵심 기능이다.
- LLM(거대 언어 모델)의 기본 능력은 매우 광범위하기 때문에, 명시적인 가드레일이 없다면 사용자의 어떤 질문에도 (심지어 서비스의 목적과 전혀 관련 없는 질문에도) 답변하려고 시도한다.

## ✈️ 실제 사례: American Airlines 챗봇

- American Airlines의 챗봇은 ChatGPT API를 기반으로 만들어졌다.
- 이 챗봇에 항공사 관련 질문이 아닌 **파이썬 코드 질문을 했을 때, 챗봇이 코드에 대한 답변을 제공**하는 이슈가 발생했다.
- **원인:** 챗봇의 역할을 '항공사 관련 정보 안내'로 한정하는 명확한 가드레일이 없었기 때문이다. 그 결과, 기반 모델인 ChatGPT의 광범위한 지식(코딩 능력 포함)이 필터링 없이 그대로 노출되었다.
- 이는 불필요한 API 토큰 비용을 발생시킬 뿐만 아니라, 브랜드의 전문성과 신뢰도를 떨어뜨릴 수 있는 심각한 문제다.

## 🤔 느낀 점 및 적용할 점 (Feelings & Application)

- 단순히 좋은 성능의 LLM을 가져다 쓰는 것만으로는 성공적인 AI 에이전트를 만들 수 없다는 것을 깨달았다. **'무엇을 하게 할 것인가' 만큼 '무엇을 못하게 할 것인가'를 정의하는 것**이 중요하다.
- 앞으로 AI 에이전트를 기획하거나 개발할 때, 가장 먼저 "이 에이전트의 명확한 역할 범위는 무엇인가?"를 정의하고, 그 범위를 벗어나는 질문이나 요청을 어떻게 처리할지에 대한 **가드레일 정책을 반드시 수립**해야겠다.
- 예를 들어, 부동산 챗봇을 만든다면 "부동산과 관련 없는 질문에는 '저는 부동산 전문 챗봇이라 해당 질문에는 답변하기 어렵습니다.'라고 정중히 거절하고, 다시 부동산 관련 질문을 하도록 유도해야 한다." 와 같은 구체적인 규칙을 정립해야 한다.
